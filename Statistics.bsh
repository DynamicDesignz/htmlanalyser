:

init() {
	[ ! -d analysis ] && mkdir analysis
	cd analysis
	[ `ls -l | wc -l` > 0 ] && rm *
	cd ..
	[ ! -d downloads ] && mkdir downloads
	cd downloads
	[ `ls -l | wc -l` > 0 ] && rm *

	cd ..
}

remove() {
  cd downloads
  rm *
}

analyseLinks() {

	sed 's/'\>\<'/\>\'$'\n\</g' $FILENAME > cleaned.html # Seperate tags in poorly compiled html code
	grep '<a' cleaned.html > anchor.txt
	
	grep -o "href='h.*'" < anchor.txt > href.txt 
	grep -o 'href="h.*"' < anchor.txt >> href.txt # Two ways of inserting a link
	
	touch hrefCleaned1.txt
	while read p; do
		set -- $p
		echo $1
	done < href.txt >> hrefCleaned1.txt
	sed 's/>/ /g' hrefCleaned1.txt > hrefCleaned2.txt
	rm hrefCleaned1.txt
	
	touch hrefCleaned3.txt
	while read p; do
		set -- $p
		echo $1
	done < hrefCleaned2.txt >> hrefCleaned3.txt
	grep -o "http.*[^\'\"]" < hrefCleaned3.txt > links.txt
	rm hrefCleaned3.txt
	
	sort -u links.txt > uniqueLinks.txt

	touch sameDomain.txt
	while read url; do

		URL=$( echo $url )
		extractDomain
		set -- $( head -1 temp1 )
		THISDOMAIN=$( echo $1 )
		rm temp1 temp2
		
		if [ "$( echo $DOMAIN )" == "$( echo $THISDOMAIN )" ]; then
			echo $URL >> sameDomain.txt
		fi

	done < uniqueLinks.txt
	# grep $DOMAIN < uniqueLinks.txt > sameDomain.txt # Not good enough
	sort -u sameDomain.txt > linksMasterListSorted.txt
	rm sameDomain.txt
}

downloadChildren() {

	touch visitedLinks.txt

	for i in $(seq 1 $LEVEL); do
	
		CHILD=`echo $i` # Depth of download
		PARENT=`expr $CHILD - 1` # Depth of analysis
		ITERATION=0
		
		for j in $DOMAIN_$PARENT_*.html;  do
			
			FILENAME=`echo $j`
			analyseLinks
			
			while read url; do
			
				URL=`echo $url`
				if [ "$( grep ^$URL$ < visitedLinks.txt )" == "" ]; then
					ITERATION=`expr $ITERATION + 1`
					downloadPage
					echo $URL >> visitedLinks.txt
				fi

			done < linksMasterListSorted.txt
			
		done
		
	done
}

downloadPage() {

	curl -sS $URL > ${DOMAIN}_${CHILD}_${ITERATION}.html

}

extractDomain() {

	touch temp1
	echo $URL > temp1
	HTTP="http.\/\/"
	sed 's/'${HTTP}'//' temp1 > temp2
	sed 's/\./ /' temp2 > temp1

}

downloadIndex() {

	extractDomain
	set -- $( head -1 temp1 )
	DOMAIN=$( echo $1 ) # Define domain for analysis
	rm temp1 temp2
	curl -sS $URL > ${DOMAIN}_0_0.html

}

downloadManager() {
	[ ! -d downloads ] && mkdir downloads
	cd downloads
	downloadIndex
	[ $LEVEL -gt 0 ] && downloadChildren
}

# analyse() {

# }

# create() {

# }


case $1 in
-z) init;;
-c) remove;;
-[0-9]) LEVEL=$( echo $1 | tail -c 2 ); URL=`echo $2`; downloadManager;;
-a) analyse;;
-h) create;;
-l) analyseLinks;;
esac
